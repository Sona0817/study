{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "993e6827-ca62-40ab-8ec0-ad3cbc56e02d",
   "metadata": {},
   "source": [
    "# DACON 신약개발AI 경진대회\n",
    "https://dacon.io/competitions/official/236127/data\n",
    "- SMILES: 화합물 분자구조\n",
    "- MLM: Mouse Liver Microsome - 쥐의 간 조직 중 미세한 부분에서 발견된 어떤 화학물질 또는 약물의 대사 속도, 반감기를 나타내는 데이터로 약물 대사 연구와 독성 예측에 중요한 역할\n",
    "- HLM: Human Liver Microsome - 인간의 간 조직 중 미세한 부분에서 발견된 어떤 화학물질 또는 약물의 대사 소도, 반감기를 나타내는 데이터로 인간의 약물 대사 연구와 **약물 안전성 평가**에 사용\n",
    "- AlogP: 화학물질의 지용성을 나타내는 지표 - 화학물질이 유기 용매와 물 사이에서 어떻게 분배되는지 나타내며, 약물 용매속성 및 대사에 영향을 미침\n",
    "- Molecular_Weight: 화학물질의 분자량 - 화학적 특성과 생물학적 활성에 영향을 줄 수 있음\n",
    "- Num_H_Accptors: 화학물질 내에서 수소 원자가 수소 결합을 받을 수 있는 원자 수 - 물질의 상호작용 및 화학적 특성에 영향을 미침\n",
    "- Num_H_Donors: 화학물질 내에서 수소 원자라 수소 결합을 형성할 수 있는 원자 수 - 물질의 상호작용 및 화학적 특성에 영향을 미침\n",
    "- Hum_RotatableBonds: 화학물질 내에서 회전이 가능한 결합 수 - 구조의 유연성을 나타내며, 약물의 생물학적 이용 가능성에 영향을 미침\n",
    "- LogD: 화학물질의 분배 계수 - 용매특성과 ph에 다른 분배 특성을 평가하는데 사용\n",
    "- Molecular_PolarSurfaceArea: 분자 내 극성 표면 면적 - 극성 및 용해도 평가에 사용\n",
    "\n",
    "HLM, MLM은 대사효소와 화합물을 30분 동안 반응시킨 후  \n",
    "대사되지 않고 남아있는 화합물의 양을 측정함으로 화합물간의 대사효소에 대한 안정성 평가 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c13f6f4d-7680-4f37-96a7-39378c39ad45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61c89b85-567c-4228-91ea-4c20c88c294f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>SMILES</th>\n",
       "      <th>MLM</th>\n",
       "      <th>HLM</th>\n",
       "      <th>AlogP</th>\n",
       "      <th>Molecular_Weight</th>\n",
       "      <th>Num_H_Acceptors</th>\n",
       "      <th>Num_H_Donors</th>\n",
       "      <th>Num_RotatableBonds</th>\n",
       "      <th>LogD</th>\n",
       "      <th>Molecular_PolarSurfaceArea</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAIN_0000</td>\n",
       "      <td>CCOc1ccc(CNC(=O)c2cc(-c3sc(C)nc3C)n[nH]2)cc1OCC</td>\n",
       "      <td>26.010</td>\n",
       "      <td>50.680</td>\n",
       "      <td>3.259</td>\n",
       "      <td>400.495</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3.259</td>\n",
       "      <td>117.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN_0001</td>\n",
       "      <td>Cc1nc(C)c(CN2CC(C)C(=O)Nc3ccccc32)s1</td>\n",
       "      <td>29.270</td>\n",
       "      <td>50.590</td>\n",
       "      <td>2.169</td>\n",
       "      <td>301.407</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.172</td>\n",
       "      <td>73.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN_0002</td>\n",
       "      <td>CCCN1CCN(c2nn3nnnc3c3ccccc23)CC1</td>\n",
       "      <td>5.586</td>\n",
       "      <td>80.892</td>\n",
       "      <td>1.593</td>\n",
       "      <td>297.358</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.585</td>\n",
       "      <td>62.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAIN_0003</td>\n",
       "      <td>Cc1ccc(-c2ccc(-n3nc(C)c(S(=O)(=O)N4CCN(C5CCCCC...</td>\n",
       "      <td>5.710</td>\n",
       "      <td>2.000</td>\n",
       "      <td>4.771</td>\n",
       "      <td>494.652</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3.475</td>\n",
       "      <td>92.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAIN_0004</td>\n",
       "      <td>Cc1ccc2c(c1)N(C(=O)c1ccncc1)CC(C)O2</td>\n",
       "      <td>93.270</td>\n",
       "      <td>99.990</td>\n",
       "      <td>2.335</td>\n",
       "      <td>268.310</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.337</td>\n",
       "      <td>42.43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                             SMILES     MLM  \\\n",
       "0  TRAIN_0000    CCOc1ccc(CNC(=O)c2cc(-c3sc(C)nc3C)n[nH]2)cc1OCC  26.010   \n",
       "1  TRAIN_0001               Cc1nc(C)c(CN2CC(C)C(=O)Nc3ccccc32)s1  29.270   \n",
       "2  TRAIN_0002                   CCCN1CCN(c2nn3nnnc3c3ccccc23)CC1   5.586   \n",
       "3  TRAIN_0003  Cc1ccc(-c2ccc(-n3nc(C)c(S(=O)(=O)N4CCN(C5CCCCC...   5.710   \n",
       "4  TRAIN_0004                Cc1ccc2c(c1)N(C(=O)c1ccncc1)CC(C)O2  93.270   \n",
       "\n",
       "      HLM  AlogP  Molecular_Weight  Num_H_Acceptors  Num_H_Donors  \\\n",
       "0  50.680  3.259           400.495                5             2   \n",
       "1  50.590  2.169           301.407                2             1   \n",
       "2  80.892  1.593           297.358                5             0   \n",
       "3   2.000  4.771           494.652                6             0   \n",
       "4  99.990  2.335           268.310                3             0   \n",
       "\n",
       "   Num_RotatableBonds   LogD  Molecular_PolarSurfaceArea  \n",
       "0                   8  3.259                      117.37  \n",
       "1                   2  2.172                       73.47  \n",
       "2                   3  1.585                       62.45  \n",
       "3                   5  3.475                       92.60  \n",
       "4                   1  2.337                       42.43  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('./train.csv')\n",
    "test = pd.read_csv('./test.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77b0c7a3-93ee-4699-9b33-48e6be4a5340",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>SMILES</th>\n",
       "      <th>AlogP</th>\n",
       "      <th>Molecular_Weight</th>\n",
       "      <th>Num_H_Acceptors</th>\n",
       "      <th>Num_H_Donors</th>\n",
       "      <th>Num_RotatableBonds</th>\n",
       "      <th>LogD</th>\n",
       "      <th>Molecular_PolarSurfaceArea</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_000</td>\n",
       "      <td>CC(C)Nc1ccnc(N2CCN(Cc3cccs3)C(CCO)C2)n1</td>\n",
       "      <td>2.641</td>\n",
       "      <td>361.505</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2.635</td>\n",
       "      <td>92.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_001</td>\n",
       "      <td>COc1cc(=O)n(-c2ccccc2)cc1C(=O)N1CCC2(CC1)OCCO2</td>\n",
       "      <td>0.585</td>\n",
       "      <td>370.399</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.585</td>\n",
       "      <td>68.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_002</td>\n",
       "      <td>Cc1cccc(NC(=N)/N=c2\\nc(O)c(Cc3ccccc3)c(C)[nH]2)c1</td>\n",
       "      <td>4.276</td>\n",
       "      <td>347.414</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4.290</td>\n",
       "      <td>92.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_003</td>\n",
       "      <td>O=C(c1nc2ncccn2n1)N1CCCn2cc(-c3ccccc3)nc21</td>\n",
       "      <td>1.795</td>\n",
       "      <td>345.358</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.795</td>\n",
       "      <td>81.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_004</td>\n",
       "      <td>CCN1CCN(C(=O)c2cc3c(=O)n4cc(C)ccc4nc3n2C)CC1</td>\n",
       "      <td>1.219</td>\n",
       "      <td>353.418</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.169</td>\n",
       "      <td>61.15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                             SMILES  AlogP  \\\n",
       "0  TEST_000            CC(C)Nc1ccnc(N2CCN(Cc3cccs3)C(CCO)C2)n1  2.641   \n",
       "1  TEST_001     COc1cc(=O)n(-c2ccccc2)cc1C(=O)N1CCC2(CC1)OCCO2  0.585   \n",
       "2  TEST_002  Cc1cccc(NC(=N)/N=c2\\nc(O)c(Cc3ccccc3)c(C)[nH]2)c1  4.276   \n",
       "3  TEST_003         O=C(c1nc2ncccn2n1)N1CCCn2cc(-c3ccccc3)nc21  1.795   \n",
       "4  TEST_004       CCN1CCN(C(=O)c2cc3c(=O)n4cc(C)ccc4nc3n2C)CC1  1.219   \n",
       "\n",
       "   Molecular_Weight  Num_H_Acceptors  Num_H_Donors  Num_RotatableBonds   LogD  \\\n",
       "0           361.505                4             2                   7  2.635   \n",
       "1           370.399                5             0                   3  0.585   \n",
       "2           347.414                4             4                   5  4.290   \n",
       "3           345.358                5             0                   2  1.795   \n",
       "4           353.418                4             0                   2  0.169   \n",
       "\n",
       "   Molecular_PolarSurfaceArea  \n",
       "0                       92.76  \n",
       "1                       68.31  \n",
       "2                       92.86  \n",
       "3                       81.21  \n",
       "4                       61.15  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea9cd457-7333-455f-b607-e06b299b4e23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                            0\n",
       "SMILES                        0\n",
       "MLM                           0\n",
       "HLM                           0\n",
       "AlogP                         2\n",
       "Molecular_Weight              0\n",
       "Num_H_Acceptors               0\n",
       "Num_H_Donors                  0\n",
       "Num_RotatableBonds            0\n",
       "LogD                          0\n",
       "Molecular_PolarSurfaceArea    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29931486-f060-48d0-9dcf-181e042f576e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a87c0c9e-b3e4-45e2-96a8-143039c98d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "train1 = train.drop('MLM', axis=1)\n",
    "train2 = train.drop('HLM', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f336e870-09df-4333-9f54-6822593bf2cd",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20231009_074110/\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20231009_074110/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.8.15\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 21.6.0: Mon Apr 24 21:11:28 PDT 2023; root:xnu-8020.240.18.701.5~1/RELEASE_ARM64_T8110\n",
      "Disk Space Avail:   99.47 GB / 494.38 GB (20.1%)\n",
      "Train Data Rows:    3496\n",
      "Train Data Columns: 9\n",
      "Label Column: MLM\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    6661.0 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.78 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['id']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('object', []) : 1 | ['id']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 4 | ['AlogP', 'Molecular_Weight', 'LogD', 'Molecular_PolarSurfaceArea']\n",
      "\t\t('int', [])    : 3 | ['Num_H_Acceptors', 'Num_H_Donors', 'Num_RotatableBonds']\n",
      "\t\t('object', []) : 1 | ['SMILES']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) : 1 | ['SMILES']\n",
      "\t\t('float', [])    : 4 | ['AlogP', 'Molecular_Weight', 'LogD', 'Molecular_PolarSurfaceArea']\n",
      "\t\t('int', [])      : 3 | ['Num_H_Acceptors', 'Num_H_Donors', 'Num_RotatableBonds']\n",
      "\t0.1s = Fit runtime\n",
      "\t8 features in original data used to generate 8 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.2 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.09s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.14302059496567507, Train Rows: 2995, Val Rows: 501\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t-37.4305\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t-37.4324\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t-32.2105\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.59s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t-32.4343\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.11s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ...\n",
      "\t-32.9599\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.5s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t-32.1982\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.13s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ...\n",
      "\t-33.2007\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.26s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t-31.8487\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.3s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t-32.4264\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.54s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t-34.9055\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.74s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t-32.5757\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.53s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-31.7603\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.09s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 13.08s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20231009_074110/\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<autogluon.tabular.predictor.predictor.TabularPredictor at 0x283dbabe0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MLM 회귀예측\n",
    "model = TabularPredictor(label='MLM', problem_type='regression')\n",
    "model.fit(train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31933283-6360-4025-9af5-2d748cef6e70",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "train and valid dataset categorical_feature do not match.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 베스트 모델 예측\u001b[39;00m\n\u001b[1;32m      2\u001b[0m best_model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39m_trainer\u001b[38;5;241m.\u001b[39mload_model(model\u001b[38;5;241m.\u001b[39mget_model_best())\n\u001b[0;32m----> 3\u001b[0m mlm_pred \u001b[38;5;241m=\u001b[39m \u001b[43mbest_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/sona/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py:918\u001b[0m, in \u001b[0;36mAbstractModel.predict\u001b[0;34m(self, X, **kwargs)\u001b[0m\n\u001b[1;32m    912\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    913\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;124;03m    Returns class predictions of X.\u001b[39;00m\n\u001b[1;32m    915\u001b[0m \u001b[38;5;124;03m    For binary and multiclass problems, this returns the predicted class labels as a Series.\u001b[39;00m\n\u001b[1;32m    916\u001b[0m \u001b[38;5;124;03m    For regression problems, this returns the predicted values as a Series.\u001b[39;00m\n\u001b[1;32m    917\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 918\u001b[0m     y_pred_proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    919\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m get_pred_from_proba(y_pred_proba\u001b[38;5;241m=\u001b[39my_pred_proba, problem_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproblem_type)\n\u001b[1;32m    920\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m y_pred\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/sona/lib/python3.8/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py:345\u001b[0m, in \u001b[0;36mBaggedEnsembleModel.predict_proba\u001b[0;34m(self, X, normalize, **kwargs)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_proba\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    344\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_child(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodels[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m--> 345\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    346\u001b[0m     pred_proba \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict_proba(X\u001b[38;5;241m=\u001b[39mX, preprocess_nonadaptive\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, normalize\u001b[38;5;241m=\u001b[39mnormalize)\n\u001b[1;32m    347\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodels[\u001b[38;5;241m1\u001b[39m:]:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/sona/lib/python3.8/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py:139\u001b[0m, in \u001b[0;36mStackerEnsembleModel.preprocess\u001b[0;34m(self, X, fit, compute_base_preds, infer, model_pred_proba_dict, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    138\u001b[0m         base_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_base_model(base_model_name)\n\u001b[0;32m--> 139\u001b[0m         y_pred_proba \u001b[38;5;241m=\u001b[39m \u001b[43mbase_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m     X_stacker\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m    141\u001b[0m         y_pred_proba\n\u001b[1;32m    142\u001b[0m     )  \u001b[38;5;66;03m# TODO: This could get very large on a high class count problem. Consider capping to top N most frequent classes and merging least frequent\u001b[39;00m\n\u001b[1;32m    143\u001b[0m X_stacker \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpred_probas_to_df(X_stacker, index\u001b[38;5;241m=\u001b[39mX\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/sona/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py:931\u001b[0m, in \u001b[0;36mAbstractModel.predict_proba\u001b[0;34m(self, X, normalize, **kwargs)\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m normalize \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    930\u001b[0m     normalize \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnormalize_pred_probas\n\u001b[0;32m--> 931\u001b[0m y_pred_proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    932\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m normalize:\n\u001b[1;32m    933\u001b[0m     y_pred_proba \u001b[38;5;241m=\u001b[39m normalize_pred_probas(y_pred_proba, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproblem_type)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/sona/lib/python3.8/site-packages/autogluon/tabular/models/lgb/lgb_model.py:234\u001b[0m, in \u001b[0;36mLGBModel._predict_proba\u001b[0;34m(self, X, num_cpus, **kwargs)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_predict_proba\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, num_cpus\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    232\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 234\u001b[0m     y_pred_proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_cpus\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproblem_type \u001b[38;5;241m==\u001b[39m REGRESSION:\n\u001b[1;32m    236\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m y_pred_proba\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/sona/lib/python3.8/site-packages/lightgbm/basic.py:3538\u001b[0m, in \u001b[0;36mBooster.predict\u001b[0;34m(self, data, start_iteration, num_iteration, raw_score, pred_leaf, pred_contrib, data_has_header, is_reshape, **kwargs)\u001b[0m\n\u001b[1;32m   3536\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3537\u001b[0m         num_iteration \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 3538\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_iteration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_iteration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3539\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mraw_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred_leaf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred_contrib\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3540\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mdata_has_header\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_reshape\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/sona/lib/python3.8/site-packages/lightgbm/basic.py:820\u001b[0m, in \u001b[0;36m_InnerPredictor.predict\u001b[0;34m(self, data, start_iteration, num_iteration, raw_score, pred_leaf, pred_contrib, data_has_header, is_reshape)\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, Dataset):\n\u001b[1;32m    819\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot use Dataset instance for prediction, please use raw data instead\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 820\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43m_data_from_pandas\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpandas_categorical\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    821\u001b[0m predict_type \u001b[38;5;241m=\u001b[39m C_API_PREDICT_NORMAL\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m raw_score:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/sona/lib/python3.8/site-packages/lightgbm/basic.py:575\u001b[0m, in \u001b[0;36m_data_from_pandas\u001b[0;34m(data, feature_name, categorical_feature, pandas_categorical)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    574\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(cat_cols) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(pandas_categorical):\n\u001b[0;32m--> 575\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain and valid dataset categorical_feature do not match.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    576\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m col, category \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(cat_cols, pandas_categorical):\n\u001b[1;32m    577\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(data[col]\u001b[38;5;241m.\u001b[39mcat\u001b[38;5;241m.\u001b[39mcategories) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlist\u001b[39m(category):\n",
      "\u001b[0;31mValueError\u001b[0m: train and valid dataset categorical_feature do not match."
     ]
    }
   ],
   "source": [
    "# 베스트 모델 예측\n",
    "best_model = model._trainer.load_model(model.get_model_best())\n",
    "mlm_pred = best_model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23404da-3552-4025-96aa-4ebc13c13cea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sona",
   "language": "python",
   "name": "sona"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

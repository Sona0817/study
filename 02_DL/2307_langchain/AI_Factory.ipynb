{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a7cbe75-2dde-47c3-ac39-950944fa3dc3",
   "metadata": {},
   "source": [
    "AIFactory의 Langchain 무료강의: https://www.youtube.com/watch?v=2yv4PxE1Ks0  \n",
    "2강: https://colab.research.google.com/drive/1FRtKBT28ZZops5jtOvsRWpL_UsK2D1fz#scrollTo=C5uYZQknXLDM  \n",
    "3강: https://colab.research.google.com/drive/1yBOOmPcmPLO-REQMy4Of4T0Wa9GfBHpy#scrollTo=Yl_SXA37i4p5  \n",
    "6강: https://colab.research.google.com/drive/1w5_n2747R4os9CH5R-2uiXT3ftvuBwAj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e30c40-5357-4167-ae4b-470d6fe537ff",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 1강. 그라디오 챗봇 시작하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d9c9993-811d-4e6b-803b-47fd238ec6af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/limkahyun/opt/anaconda3/envs/langchain/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a43535fc-6e7d-4fdc-8b88-dd92ea0745a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def greet(name):\n",
    "    return \"안녕! \" + name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db4dfb43-f439-488b-b2ba-d81132d27186",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo = gr.Interface(fn=greet,\n",
    "                    inputs='text',\n",
    "                    outputs='text'\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec609a22-4a19-4174-9954-0c49c83d8519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe30081-5989-48b1-b2c1-8edfdff218f9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 2강. openAI API 사용해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8de60143-c608-4479-bc2b-4586f5ccccf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "48fe661d-180c-4850-a040-a4cc06aafa41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 환경변수에서 OPENAI_API_KEY를 가져와 openai.api_key에 입력\n",
    "os.environ['OPENAI_API_KEY'] = '-'\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "96e2032f-637c-4878-b55b-6e9ffd7c96db",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.Completion.create(model='text-davinci-003',   # 사용할 AI 모델 지정\n",
    "                                    prompt='안녕? 넌 누구니?',     # 모델에게 전달할 프롬프트 지정\n",
    "                                    max_tokens=256,            # 생성될 텍스트의 최대 토큰수 지정\n",
    "                                    temperature=0              # 0:가장 확률이 높은 텍스트 생성 1:더 다양한 텍스트 생성\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d4b75467-3b95-4ab0-98ad-e389db4e5555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"cmpl-7bPEIRlQtYLq4TvbJBwZX5Re1YOhH\",\n",
      "  \"object\": \"text_completion\",\n",
      "  \"created\": 1689149474,\n",
      "  \"model\": \"text-davinci-003\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"text\": \"\\n\\n\\uc548\\ub155\\ud558\\uc138\\uc694. \\ub098\\ub294 \\ud64d\\uae38\\ub3d9\\uc774\\uc5d0\\uc694.\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 19,\n",
      "    \"completion_tokens\": 42,\n",
      "    \"total_tokens\": 61\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5c2814-f038-45cc-8186-03edb875ff30",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 3강. openAPI와 그라디오 챗봇 연동하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26db0f83-2b65-46fc-94f5-e0d95687e6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9648bfec-39fa-41e6-8b98-8f53a3d87fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 환경변수에서 OPENAI_API_KEY를 가져와 openai.api_key에 입력\n",
    "os.environ['OPENAI_API_KEY'] = '-'\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4f8c31a-2f62-46f0-a8e3-284b9a205ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def respond(message, chat_history):  # 채팅봇의 응답을 처리하는 함수를 정의합니다.\n",
    "    \n",
    "    response = openai.Completion.create(model=\"text-davinci-003\",\n",
    "                                        prompt=message,\n",
    "                                        max_tokens=1000,\n",
    "                                        temperature=0\n",
    "                                       )\n",
    "    \n",
    "    # json에서 출력 텍스트를 저장\n",
    "    bot_message = response.choices[0].text \n",
    "    \n",
    "    # 채팅 기록에 사용자의 메시지와 봇의 응답을 추가합니다.\n",
    "    chat_history.append((message, bot_message))\n",
    "\n",
    "    return \"\", chat_history  # 수정된 채팅 기록을 반환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5ae7b41-cbd1-4486-876c-8c9870378ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyboard interruption in main thread... closing server.\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 그라디오 UI를 이용하기\n",
    "# gr.Blocks()를 사용하여 인터페이스를 생성\n",
    "with gr.Blocks() as demo:\n",
    "    # '채팅창'이라는 레이블을 가진 채팅봇 컴포넌트를 생성합니다.\n",
    "    chatbot = gr.Chatbot(label=\"채팅창\")\n",
    "    \n",
    "    # '입력'이라는 레이블을 가진 텍스트박스를 생성합니다.\n",
    "    msg = gr.Textbox(label=\"입력\")  \n",
    "    \n",
    "    # '초기화'라는 레이블을 가진 버튼을 생성합니다.\n",
    "    clear = gr.Button(\"초기화\")\n",
    "    \n",
    "    # 텍스트박스에 메시지를 입력하고 제출하면 respond 함수가 호출, [msg, chatbot]을 respond함수에 입력, respond 함수의 return도 [msg, chatbot]\n",
    "    msg.submit(respond, [msg, chatbot], [msg, chatbot])\n",
    "    \n",
    "    # '초기화' 버튼을 클릭하면 채팅 기록을 초기화합니다.\n",
    "    clear.click(lambda: None, None, chatbot, queue=False)  \n",
    "\n",
    "# 챗봇을 주고받으려면 그라디오가 계속 실행되기 때문에 종료하려면 정지버튼 누르기\n",
    "demo.launch(debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5f2ab6-66d7-489c-9703-d0aea17c08f9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 4강. 랭체인 LLM과 그라디오 챗봇 연동하기\n",
    "openai를 langchain LLM으로 교체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e7b0bb6-aae8-4982-8024-ee385faae96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.llms import OpenAI\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "890c7ee3-3399-4e0c-8b6f-8fb44437e3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 환경변수에서 OPENAI_API_KEY를 가져와 openai.api_key에 입력\n",
    "os.environ['OPENAI_API_KEY'] = '-'\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "26a6d241-6878-4887-8af3-b5e4009de6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(model_name='text-davinci-003', temperature=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd3e68d7-d0e1-41d6-a520-0a9fa5c7ed20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n안녕하세요. 나는 친구입니다.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm('안녕? 넌 누구니?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d8fb6c4a-50d8-46f2-a63f-73247165a221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그라디오 연결\n",
    "def respond(message, chat_history):\n",
    "    bot_message = llm(message)\n",
    "    chat_history.append([message, bot_message])\n",
    "    return '', chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f1064e7b-fb7e-4377-b7de-fbc33cea4fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with gr.Blocks() as demo:\n",
    "    chatbot = gr.Chatbot(label='chatting')\n",
    "    msg = gr.Textbox(label='input')\n",
    "    clear = gr.Button('reset')\n",
    "    \n",
    "    msg.submit(respond, [msg, chatbot], [msg, chatbot])\n",
    "    clear.click(lambda: None, None, chatbot, queue=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2eb0611f-4bd5-46ab-bccd-a883cfea67e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyboard interruption in main thread... closing server.\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 챗봇을 주고받으려면 그라디오가 계속 실행되기 때문에 종료하려면 정지버튼 누르기\n",
    "demo.launch(debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389160ec-ef0c-4d7e-b1b8-3df9a1b5a0d2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 5강. 랭체인 챗모델과 그라디오 챗봇 연동하기\n",
    "LLM모델에서 chatgpt 모델로 교체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "261d3a06-99af-4f3e-afbb-92f7966a20b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import AIMessage, HumanMessage, SystemMessage\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9a5ad9e-99d0-4216-a3e5-762a0e5dc476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 환경변수에서 OPENAI_API_KEY를 가져와 openai.api_key에 입력\n",
    "os.environ['OPENAI_API_KEY'] = '-'\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65322910-7877-4e68-947d-aec2f3b36e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_llm = ChatOpenAI(model='gpt-3.5-turbo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77516651-42bb-4c27-99c5-5e7b57f29404",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chat_llm([HumanMessage(content='안녕? 넌 누구니?')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7663f73c-40bb-4578-aeb0-df4b58ca9f2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'안녕! 나는 OpenAI의 인공지능 모델이야. 너에게 어떻게 도움을 줄까?'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48fc37c2-cc04-4fa5-a249-4ea2ca6c85aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그라디오 연결\n",
    "def respond(message, chat_history):\n",
    "    result = chat_llm([HumanMessage(content=message)])\n",
    "    bot_message = result.content\n",
    "    chat_history.append([message, bot_message])\n",
    "    return '', chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92ce78da-dfe5-452e-b61b-cf9df874cf7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with gr.Blocks() as demo:\n",
    "    chatbot = gr.Chatbot(label='채팅창')\n",
    "    msg = gr.Textbox(label='입력')\n",
    "    clear = gr.Button('초기화')\n",
    "    \n",
    "    msg.submit(respond, [msg, chatbot], [msg, chatbot])\n",
    "    clear.click(lambda: None, None, chatbot, queue=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8fb70b65-dbbb-49f0-ba80-8a645883fa31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyboard interruption in main thread... closing server.\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 다음셀 사용하려면 정지버튼 누르기\n",
    "demo.launch(debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fac8f6-48cb-4d63-96ff-d9d4fda6e057",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 6강. pdf기반 질의응답 챗봇\n",
    "huggingface embedding을 사용하면 비용 발생하지 않음  \n",
    "huggingface embedding을 사용하기 위해서는 아래와 같이 설치 필요\n",
    "- pip install huggingface_hub\n",
    "- pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc322f02-434b-4a60-b3ae-251520b4010f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/limkahyun/opt/anaconda3/envs/langchain/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# pdf 벡터화\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "# from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "# 랭체인 챗봇\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "\n",
    "# 프롬프트 한국어로 설정\n",
    "from langchain.prompts.chat import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "\n",
    "# 그라디오\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f074f5a8-2c04-4523-9847-572c3dce7837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChatOpenAI 사용하기 위함\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"-\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "105fc767-78d6-46d9-9854-b9cac921e6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdf샘플로 회사 브로셔 사용\n",
    "loader = PyPDFLoader(\"2023_kubwa.pdf\")\n",
    "documents = loader.load()\n",
    "\n",
    "# 파일 안에 있는 text를 일정 단위로 달라서 chunk 만들기\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b702a35-c9df-4d63-a368-552702023f3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='Manufacturing, Industrial, Healthcare 분야�데이터에�특화된 \\n컨설팅, 솔루션, 분석�플랫폼을�제공합니다. \\nOUR PRODUCT \\n& SERVICE\\n01. kubwa Company\\n02. kubwa Manufacturing\\n03. kubwa AIoT\\n04. kubwa MLOps\\n05. kubwa Use Case', metadata={'source': '2023_kubwa.pdf', 'page': 1})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1fb28f4-aef3-43c4-959d-aed286932b78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 벡터화\n",
    "# embeddings = OpenAIEmbeddings()\n",
    "embeddings = HuggingFaceEmbeddings()\n",
    "\n",
    "# 벡터 저장\n",
    "vector_store = Chroma.from_documents(texts, embeddings)\n",
    "\n",
    "# 벡터 유사도 관련성 중 k를 지정해 상위값 검색할 수 있게 설정\n",
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "daf47064-feab-4d38-9189-de9f22cd0ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# openAI 불러오기\n",
    "llm = ChatOpenAI(model_name='gpt-3.5-turbo', temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fdf87b8-6e01-41c1-9715-9d69afa94184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 체인 만들기 (문서기반 질의응답 할 수 있는 체인)\n",
    "chain = RetrievalQAWithSourcesChain.from_chain_type(llm=llm,\n",
    "                                                    chain_type='stuff',\n",
    "                                                    retriever = retriever,\n",
    "                                                    return_source_documents=True\n",
    "                                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7840378b-9a65-490c-978b-658a0406304d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'what is kubwa?', 'answer': 'Kubwa is a company that provides consulting, solutions, and analysis platforms specialized in data for the manufacturing, industrial, and healthcare sectors. It aims to create a large AI ecosystem (ecosystem) similar to the forests of the African savannah to contribute. Kubwa is derived from the Swahili word for \"BIG.\" \\n', 'sources': '2023_kubwa.pdf', 'source_documents': [Document(page_content='address  경기도�성남시�판교역로 230, 삼환하이펙스 B동 207호\\nwebsite  www.kubwa.co.kr   e-mail  kubwa@kubwa.co.kr쿱와(kubwa) 는 아프리카 스와힐리어로 BIG을 의미합니다.\\n쿱와는 아프리카 초원지대의 숲처럼 커다란 AI 생태계(에코시스템)를 만들어 기여하고자 합니다.', metadata={'source': '2023_kubwa.pdf', 'page': 7}), Document(page_content='Manufacturing, Industrial, Healthcare 분야�데이터에�특화된 \\n컨설팅, 솔루션, 분석�플랫폼을�제공합니다. \\nOUR PRODUCT \\n& SERVICE\\n01. kubwa Company\\n02. kubwa Manufacturing\\n03. kubwa AIoT\\n04. kubwa MLOps\\n05. kubwa Use Case', metadata={'source': '2023_kubwa.pdf', 'page': 1})]}\n"
     ]
    }
   ],
   "source": [
    "q = 'what is kubwa?'\n",
    "result = chain(q)\n",
    "print(result)\n",
    "# result['answer'] : 랭체인의 답변\n",
    "# result['source'] : 답변의 근거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd939ab2-a273-4724-88fe-57b132b42019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 프롬프트 한국어로 설정\n",
    "system_template=\"\"\"Use the following pieces of context to answer the users question shortly.\n",
    "Given the following summaries of a long document and a question, create a final answer with references (\"SOURCES\"),\n",
    "use \"SOURCES\" in capital letters regardless of the number of sources.\n",
    "If you don't know the answer, just say that \"I don't know\", don't try to make up an answer.\n",
    "----------------\n",
    "{summaries}\n",
    "You MUST answer in Korean and in Markdown format:\"\"\"\n",
    "\n",
    "messages = [SystemMessagePromptTemplate.from_template(system_template),\n",
    "            HumanMessagePromptTemplate.from_template(\"{question}\")\n",
    "           ]\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c42da981-632b-4c3e-a1e1-44240f132945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 체인 만들기 (한국어 설정)\n",
    "chain = RetrievalQAWithSourcesChain.from_chain_type(llm=llm,\n",
    "                                                    chain_type='stuff',\n",
    "                                                    retriever=retriever,\n",
    "                                                    return_source_documents=True,\n",
    "                                                    chain_type_kwargs={'prompt':prompt}\n",
    "                                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "646e4aeb-dcbb-4d2d-bc93-50710ec598ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "회사 이름은 쿱와(kubwa)입니다. [SOURCE]\n"
     ]
    }
   ],
   "source": [
    "q = '회사 이름이 뭐야?'\n",
    "result = chain(q)\n",
    "print(result['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f6bffdb-ee6c-426e-b720-bfd12311aa66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "파일:  2023_kubwa.pdf\n",
      "내용:  address  경기도�성남시�판교역로 230, 삼환하이펙스 B동 207호 website  www.kubwa.co.kr   e-mail  kubwa@kubwa.co.kr쿱와(kub\n",
      "페이지:  7\n",
      "파일:  2023_kubwa.pdf\n",
      "내용:  Manufacturing, Industrial, Healthcare 분야�데이터에�특화된  컨설팅, 솔루션, 분석�플랫폼을�제공합니다.  OUR PRODUCT  & SERVICE \n",
      "페이지:  1\n"
     ]
    }
   ],
   "source": [
    "# 내용확인\n",
    "for doc in result['source_documents']:\n",
    "    print('파일: ', doc.metadata['source'])\n",
    "    print('내용: ', doc.page_content[0:100].replace('\\n', ' '))\n",
    "    print('페이지: ', doc.metadata['page'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8741a1d-56c5-4091-a7f4-c5b6ce11b609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그라디오 연결\n",
    "def respond(message, chat_history):\n",
    "\n",
    "    result = chain(message)\n",
    "    bot_message = result['answer']\n",
    "\n",
    "    for i, doc in enumerate(result['source_documents']):\n",
    "        bot_message += '\\n답변출처' + str(i+1) + ') ' + doc.metadata['source'] + '/ page' + str(doc.metadata['page'])\n",
    "\n",
    "    chat_history.append((message, bot_message))\n",
    "\n",
    "    return \"\", chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "60f1a8e1-19b9-460c-a74c-08722ce41209",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bw/hc1k__h51gsbssz_qpxf16jr0000gn/T/ipykernel_1242/2704861026.py:2: GradioDeprecationWarning: The `style` method is deprecated. Please set these arguments in the constructor instead.\n",
      "  chatbot = gr.Chatbot(label=\"채팅창\").style(height=500)\n"
     ]
    }
   ],
   "source": [
    "with gr.Blocks() as demo:\n",
    "    chatbot = gr.Chatbot(label=\"채팅창\").style(height=500)\n",
    "    msg = gr.Textbox(label=\"입력\")\n",
    "    clear = gr.Button(\"초기화\")\n",
    "\n",
    "    msg.submit(respond, [msg, chatbot], [msg, chatbot])\n",
    "    clear.click(lambda: None, None, chatbot, queue=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68bd286-e0ae-40c4-8efb-e79494f98192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "demo.launch(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cddb3aa-b684-436a-873b-90b130f50a6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "langchain"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c247c279-f3e9-48e2-b6d6-5846dbf3ff92",
   "metadata": {},
   "source": [
    "# Binary Classification\n",
    "## 1. Load Dataset from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc64656b-045b-492e-beb9-d48d6195483d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9dc3c8c2-d1db-4d63-9323-e4ea8772ed6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "cancer = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71f3b33b-28fc-4d8a-8ff3-beb9604dbd9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>...</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "564        21.56         22.39          142.00     1479.0          0.11100   \n",
       "565        20.13         28.25          131.20     1261.0          0.09780   \n",
       "566        16.60         28.08          108.30      858.1          0.08455   \n",
       "567        20.60         29.33          140.10     1265.0          0.11780   \n",
       "568         7.76         24.54           47.92      181.0          0.05263   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "564           0.11590         0.24390              0.13890         0.1726   \n",
       "565           0.10340         0.14400              0.09791         0.1752   \n",
       "566           0.10230         0.09251              0.05302         0.1590   \n",
       "567           0.27700         0.35140              0.15200         0.2397   \n",
       "568           0.04362         0.00000              0.00000         0.1587   \n",
       "\n",
       "     mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "564                 0.05623  ...          26.40           166.10      2027.0   \n",
       "565                 0.05533  ...          38.25           155.00      1731.0   \n",
       "566                 0.05648  ...          34.12           126.70      1124.0   \n",
       "567                 0.07016  ...          39.42           184.60      1821.0   \n",
       "568                 0.05884  ...          30.37            59.16       268.6   \n",
       "\n",
       "     worst smoothness  worst compactness  worst concavity  \\\n",
       "564           0.14100            0.21130           0.4107   \n",
       "565           0.11660            0.19220           0.3215   \n",
       "566           0.11390            0.30940           0.3403   \n",
       "567           0.16500            0.86810           0.9387   \n",
       "568           0.08996            0.06444           0.0000   \n",
       "\n",
       "     worst concave points  worst symmetry  worst fractal dimension  class  \n",
       "564                0.2216          0.2060                  0.07115      0  \n",
       "565                0.1628          0.2572                  0.06637      0  \n",
       "566                0.1418          0.2218                  0.07820      0  \n",
       "567                0.2650          0.4087                  0.12400      0  \n",
       "568                0.0000          0.2871                  0.07039      1  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(cancer.data, columns=cancer.feature_names)\n",
    "df['class'] = cancer.target\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2852c99-e334-4950-a1ee-57083c32cb9d",
   "metadata": {},
   "source": [
    "## 2. Convert to PyTorch Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03f99907-76da-4cd9-b33a-dd1983d2d323",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66ca7ee4-50ac-46a9-9a1c-542e02f3743e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([569, 31])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = torch.from_numpy(df.values).float()\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eee3013c-8812-465f-ad29-49240a9aafdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([569, 30]) torch.Size([569, 1])\n"
     ]
    }
   ],
   "source": [
    "x = data[:, :-1]\n",
    "y = data[:, -1:]\n",
    "\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ed4a234-ddc3-415a-835d-025a3bbdb8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, valid, test ratio\n",
    "ratios = [.6, .2, .2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65a58668-f699-47cb-9e61-d82e3226d614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 341 / valid 113 / test 115 samples.\n"
     ]
    }
   ],
   "source": [
    "train_cnt = int(data.size(0)*ratios[0]) # data.size(0)=569, ratios[0]=.6\n",
    "valid_cnt = int(data.size(0)*ratios[1]) # data.size(0)=569, ratios[1]=.2\n",
    "test_cnt = data.size(0) - train_cnt - valid_cnt\n",
    "cnts = [train_cnt, valid_cnt, test_cnt]\n",
    "\n",
    "print(\"train %d / valid %d / test %d samples.\" % (train_cnt, valid_cnt, test_cnt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6292ed1-19fa-4f1c-abca-3063144d6b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([341, 30]) torch.Size([341, 1])\n",
      "torch.Size([113, 30]) torch.Size([113, 1])\n",
      "torch.Size([115, 30]) torch.Size([115, 1])\n"
     ]
    }
   ],
   "source": [
    "# 데이터 섞고 분리\n",
    "indices = torch.randperm(data.size(0))\n",
    "\n",
    "x = torch.index_select(x, dim=0, index=indices)\n",
    "y = torch.index_select(y, dim=0, index=indices)\n",
    "\n",
    "x = x.split(cnts, dim=0)\n",
    "y = y.split(cnts, dim=0)\n",
    "\n",
    "for x_i, y_i in zip(x, y):\n",
    "    print(x_i.size(), y_i.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42bf49a6-b30c-4e9e-a621-72280607d75d",
   "metadata": {},
   "source": [
    "## 3. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7c66091c-6f2e-4b6f-8d1a-c8163b09c665",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0].size(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fd90818e-b410-4229-a4e2-a68bd1007d09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>-0.598040</td>\n",
       "      <td>-1.134751</td>\n",
       "      <td>-0.581492</td>\n",
       "      <td>-0.593860</td>\n",
       "      <td>0.487012</td>\n",
       "      <td>-0.236446</td>\n",
       "      <td>-0.286961</td>\n",
       "      <td>-0.559392</td>\n",
       "      <td>-0.482309</td>\n",
       "      <td>-0.328681</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.524974</td>\n",
       "      <td>-0.843474</td>\n",
       "      <td>-0.519110</td>\n",
       "      <td>-0.527439</td>\n",
       "      <td>0.739495</td>\n",
       "      <td>-0.231534</td>\n",
       "      <td>0.173341</td>\n",
       "      <td>-0.740064</td>\n",
       "      <td>-0.249585</td>\n",
       "      <td>-0.052583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>0.116243</td>\n",
       "      <td>-1.297664</td>\n",
       "      <td>0.080138</td>\n",
       "      <td>-0.029882</td>\n",
       "      <td>0.986523</td>\n",
       "      <td>-0.206325</td>\n",
       "      <td>-0.248276</td>\n",
       "      <td>0.424989</td>\n",
       "      <td>-0.577048</td>\n",
       "      <td>-0.216287</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.097328</td>\n",
       "      <td>-1.496144</td>\n",
       "      <td>-0.120461</td>\n",
       "      <td>-0.230124</td>\n",
       "      <td>0.084105</td>\n",
       "      <td>-0.669117</td>\n",
       "      <td>-0.652055</td>\n",
       "      <td>-0.105647</td>\n",
       "      <td>-0.490419</td>\n",
       "      <td>-0.322731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>1.518888</td>\n",
       "      <td>-0.244997</td>\n",
       "      <td>1.474497</td>\n",
       "      <td>1.419273</td>\n",
       "      <td>0.531087</td>\n",
       "      <td>0.833453</td>\n",
       "      <td>0.947382</td>\n",
       "      <td>1.205189</td>\n",
       "      <td>0.343817</td>\n",
       "      <td>-0.546266</td>\n",
       "      <td>...</td>\n",
       "      <td>1.577619</td>\n",
       "      <td>0.532845</td>\n",
       "      <td>1.366181</td>\n",
       "      <td>1.330375</td>\n",
       "      <td>0.846497</td>\n",
       "      <td>0.796594</td>\n",
       "      <td>0.796448</td>\n",
       "      <td>1.706317</td>\n",
       "      <td>1.190296</td>\n",
       "      <td>-0.335386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>1.573611</td>\n",
       "      <td>1.464332</td>\n",
       "      <td>1.495408</td>\n",
       "      <td>1.552382</td>\n",
       "      <td>0.494358</td>\n",
       "      <td>-0.080018</td>\n",
       "      <td>0.984407</td>\n",
       "      <td>1.099814</td>\n",
       "      <td>-0.527784</td>\n",
       "      <td>-1.268184</td>\n",
       "      <td>...</td>\n",
       "      <td>1.084987</td>\n",
       "      <td>0.932756</td>\n",
       "      <td>0.986228</td>\n",
       "      <td>0.962508</td>\n",
       "      <td>0.891081</td>\n",
       "      <td>-0.432254</td>\n",
       "      <td>0.629597</td>\n",
       "      <td>0.502425</td>\n",
       "      <td>-1.025037</td>\n",
       "      <td>-1.268524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>-0.488593</td>\n",
       "      <td>-0.540747</td>\n",
       "      <td>-0.558072</td>\n",
       "      <td>-0.512837</td>\n",
       "      <td>-1.535272</td>\n",
       "      <td>-1.368596</td>\n",
       "      <td>-0.957245</td>\n",
       "      <td>-0.835313</td>\n",
       "      <td>-1.251591</td>\n",
       "      <td>-1.023221</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.705256</td>\n",
       "      <td>-0.928304</td>\n",
       "      <td>-0.763969</td>\n",
       "      <td>-0.645973</td>\n",
       "      <td>-2.172309</td>\n",
       "      <td>-1.318910</td>\n",
       "      <td>-1.217724</td>\n",
       "      <td>-1.309232</td>\n",
       "      <td>-1.694590</td>\n",
       "      <td>-1.356006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "336    -0.598040     -1.134751       -0.581492  -0.593860         0.487012   \n",
       "337     0.116243     -1.297664        0.080138  -0.029882         0.986523   \n",
       "338     1.518888     -0.244997        1.474497   1.419273         0.531087   \n",
       "339     1.573611      1.464332        1.495408   1.552382         0.494358   \n",
       "340    -0.488593     -0.540747       -0.558072  -0.512837        -1.535272   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "336         -0.236446       -0.286961            -0.559392      -0.482309   \n",
       "337         -0.206325       -0.248276             0.424989      -0.577048   \n",
       "338          0.833453        0.947382             1.205189       0.343817   \n",
       "339         -0.080018        0.984407             1.099814      -0.527784   \n",
       "340         -1.368596       -0.957245            -0.835313      -1.251591   \n",
       "\n",
       "     mean fractal dimension  ...  worst radius  worst texture  \\\n",
       "336               -0.328681  ...     -0.524974      -0.843474   \n",
       "337               -0.216287  ...     -0.097328      -1.496144   \n",
       "338               -0.546266  ...      1.577619       0.532845   \n",
       "339               -1.268184  ...      1.084987       0.932756   \n",
       "340               -1.023221  ...     -0.705256      -0.928304   \n",
       "\n",
       "     worst perimeter  worst area  worst smoothness  worst compactness  \\\n",
       "336        -0.519110   -0.527439          0.739495          -0.231534   \n",
       "337        -0.120461   -0.230124          0.084105          -0.669117   \n",
       "338         1.366181    1.330375          0.846497           0.796594   \n",
       "339         0.986228    0.962508          0.891081          -0.432254   \n",
       "340        -0.763969   -0.645973         -2.172309          -1.318910   \n",
       "\n",
       "     worst concavity  worst concave points  worst symmetry  \\\n",
       "336         0.173341             -0.740064       -0.249585   \n",
       "337        -0.652055             -0.105647       -0.490419   \n",
       "338         0.796448              1.706317        1.190296   \n",
       "339         0.629597              0.502425       -1.025037   \n",
       "340        -1.217724             -1.309232       -1.694590   \n",
       "\n",
       "     worst fractal dimension  \n",
       "336                -0.052583  \n",
       "337                -0.322731  \n",
       "338                -0.335386  \n",
       "339                -1.268524  \n",
       "340                -1.356006  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(x[0].numpy()) # x[0] = x_train\n",
    "\n",
    "x = [torch.from_numpy(scaler.transform(x[0].numpy())).float(),\n",
    "     torch.from_numpy(scaler.transform(x[1].numpy())).float(),\n",
    "     torch.from_numpy(scaler.transform(x[2].numpy())).float()]\n",
    "\n",
    "df = pd.DataFrame(x[0].numpy(), columns=cancer.feature_names)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cda901f-868b-46aa-bb20-e4d7b0833cae",
   "metadata": {},
   "source": [
    "## 4. Build Model & Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "74e96270-9b28-4388-9061-cd14ee54990f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=30, out_features=25, bias=True)\n",
       "  (1): LeakyReLU(negative_slope=0.01)\n",
       "  (2): Linear(in_features=25, out_features=20, bias=True)\n",
       "  (3): LeakyReLU(negative_slope=0.01)\n",
       "  (4): Linear(in_features=20, out_features=15, bias=True)\n",
       "  (5): LeakyReLU(negative_slope=0.01)\n",
       "  (6): Linear(in_features=15, out_features=10, bias=True)\n",
       "  (7): LeakyReLU(negative_slope=0.01)\n",
       "  (8): Linear(in_features=10, out_features=5, bias=True)\n",
       "  (9): LeakyReLU(negative_slope=0.01)\n",
       "  (10): Linear(in_features=5, out_features=1, bias=True)\n",
       "  (11): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(x[0].size(-1), 25), # x[0].size(-1) = x_train의 컬럼수\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Linear(25, 20),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Linear(20, 15),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Linear(15, 10),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Linear(10, 5),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Linear(5, y[0].size(-1)),\n",
    "    nn.Sigmoid(), # 이진분류\n",
    ")\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e2841e49-0b17-47ed-b5d6-46a24bb21960",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f75c6d8-3af4-472a-a072-e734c29ce071",
   "metadata": {},
   "source": [
    "## 5. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e89db5ce-fc25-4adc-be1e-88367e88b18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10000\n",
    "batch_size = 32\n",
    "print_interval = 100\n",
    "early_stop = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "34209f85-408f-48d0-9ec9-2ff08ed3ce50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "lowest_loss = np.inf # 이후 최저loss 찾는데 사용할 변수\n",
    "best_model = None \n",
    "\n",
    "lowest_epoch = np.inf # 이후 최저loss를 가지는 epoch 찾는데 사용할 변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a83b9115-3497-4d43-93f4-13f3ed8d2204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100: train loss=1.6807e-04  valid_loss=4.7265e-02  lowest_loss=2.5532e-02\n",
      "Epoch 200: train loss=1.9054e-05  valid_loss=6.1857e-02  lowest_loss=2.5532e-02\n",
      "Epoch 300: train loss=6.3405e-06  valid_loss=6.4396e-02  lowest_loss=2.5532e-02\n",
      "Epoch 400: train loss=2.5916e-06  valid_loss=6.6352e-02  lowest_loss=2.5532e-02\n",
      "Epoch 500: train loss=1.1828e-06  valid_loss=6.8140e-02  lowest_loss=2.5532e-02\n",
      "Epoch 600: train loss=5.8275e-07  valid_loss=6.9665e-02  lowest_loss=2.5532e-02\n",
      "Epoch 700: train loss=2.7873e-07  valid_loss=7.0754e-02  lowest_loss=2.5532e-02\n",
      "Epoch 800: train loss=1.4072e-07  valid_loss=7.1800e-02  lowest_loss=2.5532e-02\n",
      "Epoch 900: train loss=7.3152e-08  valid_loss=7.2446e-02  lowest_loss=2.5532e-02\n",
      "Epoch 1000: train loss=3.8761e-08  valid_loss=7.3143e-02  lowest_loss=2.5532e-02\n",
      "There is no improvement during last 1000 epochs.\n",
      "The best validation loss from epoch 39: 2.5532e-02\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_history, valid_history = [], []\n",
    "\n",
    "for i in range(n_epochs):\n",
    "    # 랜덤하게 데이터 섞기\n",
    "    indices = torch.randperm(x[0].size(0))\n",
    "    x_ = torch.index_select(x[0], dim=0, index=indices)\n",
    "    y_ = torch.index_select(y[0], dim=0, index=indices)\n",
    "    \n",
    "    x_ = x_.split(batch_size, dim=0)\n",
    "    y_ = y_.split(batch_size, dim=0)\n",
    "    \n",
    "    #####\n",
    "    \n",
    "    train_loss, valid_loss = 0, 0\n",
    "    y_hat = []\n",
    "    \n",
    "    # loss 찾기\n",
    "    for x_i, y_i in zip(x_, y_):\n",
    "        y_hat_i = model(x_i)\n",
    "        loss = F.binary_cross_entropy(y_hat_i, y_i)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward() # 미분\n",
    "\n",
    "        optimizer.step()   \n",
    "        train_loss += float(loss) # This is very important to prevent memory leak.\n",
    "\n",
    "    train_loss = train_loss / len(x_) # 평균 train_loss\n",
    "    \n",
    "    # no_grad() 안하면 속도가 엄청 느려짐\n",
    "    with torch.no_grad():\n",
    "        x_ = x[1].split(batch_size, dim=0)\n",
    "        y_ = y[1].split(batch_size, dim=0)\n",
    "        \n",
    "        valid_loss = 0\n",
    "        \n",
    "        for x_i, y_i in zip(x_, y_):\n",
    "            y_hat_i = model(x_i)\n",
    "            loss = F.binary_cross_entropy(y_hat_i, y_i)\n",
    "            \n",
    "            valid_loss += float(loss)\n",
    "            \n",
    "            y_hat += [y_hat_i]\n",
    "            \n",
    "    valid_loss = valid_loss / len(x_)\n",
    "    \n",
    "    train_history += [train_loss]\n",
    "    valid_history += [valid_loss]\n",
    "    \n",
    "    if (i + 1) % print_interval == 0:\n",
    "        print('Epoch %d: train loss=%.4e  valid_loss=%.4e  lowest_loss=%.4e' % (\n",
    "            i + 1,\n",
    "            train_loss,\n",
    "            valid_loss,\n",
    "            lowest_loss,\n",
    "        ))\n",
    "        \n",
    "    # valid loss 갱신 여부 best model 찾기\n",
    "    if valid_loss <= lowest_loss:\n",
    "        lowest_loss = valid_loss\n",
    "        lowest_epoch = i\n",
    "        \n",
    "        best_model = deepcopy(model.state_dict()) # model.state_dict() 모델을 딕셔너리형으로 저장\n",
    "    else:\n",
    "        if early_stop > 0 and lowest_epoch + early_stop < i + 1:\n",
    "            print(\"There is no improvement during last %d epochs.\" % early_stop)\n",
    "            break\n",
    "\n",
    "print(\"The best validation loss from epoch %d: %.4e\" % (lowest_epoch + 1, lowest_loss))\n",
    "model.load_state_dict(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e40dc9a-4f6f-48ac-a3b3-f98e9f501ea6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

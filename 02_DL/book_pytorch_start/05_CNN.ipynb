{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e7d8800-f4ce-4eed-b9b0-630d1cf3da50",
   "metadata": {},
   "source": [
    "# PyTorch로 시작하는 딥러닝 입문\n",
    "https://wikidocs.net/book/2788\n",
    "## 01. CNN으로 MNIST 분류하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "417c9962-1c22-426b-8086-3e1d9649bc2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/limkahyun/opt/anaconda3/envs/sona/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "effcd4c3-4de8-4e20-b687-53e9d0040bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape : torch.Size([1, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "# 임의의 텐서 1x1x28x28 만들기\n",
    "inputs = torch.Tensor(1, 1, 28, 28)\n",
    "print(f'input shape : {inputs.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cb49c47-a328-4db9-a623-36b3c235c1cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n"
     ]
    }
   ],
   "source": [
    "# 첫번재 합성곱층\n",
    "conv1 = nn.Conv2d(1, 32, 3, padding=1)\n",
    "print(conv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a465b7b1-5a40-4ad4-9dc2-908db6cdc2c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n"
     ]
    }
   ],
   "source": [
    "# 두번째 합성곱층\n",
    "conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "print(conv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d09384c9-c9b6-49b8-b727-cfb0067f808e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n"
     ]
    }
   ],
   "source": [
    "# 맥스풀링\n",
    "pool = nn.MaxPool2d(2)\n",
    "print(pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f931105-2262-4046-9bfc-e813f0c21fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1: torch.Size([1, 32, 28, 28])\n",
      "maxpool1: torch.Size([1, 32, 14, 14])\n",
      "conv2: torch.Size([1, 64, 14, 14])\n",
      "maxpool2: torch.Size([1, 64, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "# 연결하기\n",
    "out = conv1(inputs)\n",
    "print('conv1:', out.shape)\n",
    "\n",
    "out = pool(out)\n",
    "print('maxpool1:', out.shape)\n",
    "\n",
    "out = conv2(out)\n",
    "print('conv2:', out.shape)\n",
    "\n",
    "out = pool(out)\n",
    "print('maxpool2:', out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b87808cd-3d15-4667-a9cf-4307a7fa3504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flatten: torch.Size([1, 3136])\n"
     ]
    }
   ],
   "source": [
    "# flatten\n",
    "out = out.view(out.size(0), -1)\n",
    "print('flatten:', out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c591f0e-f175-4fbc-96ca-19103e42d7ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "# 전결합층(Fully Connteced layer;fc) 통과\n",
    "# 10은 분류 하고자 하는 갯수\n",
    "fc = nn.Linear(3136, 10)\n",
    "out = fc(out)\n",
    "print('result:', out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b7db446-d342-428a-8346-1881c68a6bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파라미터 설정\n",
    "torch.manual_seed(777)\n",
    "lr = 0.001\n",
    "n_epochs = 15\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8af55406-8fa5-4fcd-9f8b-1ab7988dba3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 정의\n",
    "mnist_train = dsets.MNIST(root='MNIST_data/', # 다운로드 경로 지정\n",
    "                          train=True,\n",
    "                          transform=transforms.ToTensor(), # 텐서로 변환\n",
    "                          download=True)\n",
    "mnist_test = dsets.MNIST(root='MNIST_data/', \n",
    "                         train=False, \n",
    "                         transform=transforms.ToTensor(), \n",
    "                         download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69a282e9-0d81-4635-99cc-55ebec176493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로더\n",
    "data_loader = torch.utils.data.DataLoader(dataset=mnist_train,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True,\n",
    "                                          drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb5b33f-332a-42d7-beec-6ba9e1c3114c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class로 모델 설계\n",
    "class CNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        # input shape torch.Size([100, 1, 28, 28])\n",
    "        # input shape (?, 28, 28, 1)\n",
    "        self.layer1 = torch.nn.Sequential(torch.nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
    "                                          # conv2d shape (?, 28, 28, 32)\n",
    "                                          torch.nn.ReLU(),\n",
    "                                          torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "                                          # pool shape (?, 14, 14, 32)\n",
    "                                         )\n",
    "        # inpust shape (?, 14, 14, 32)\n",
    "        self.layer2 = torch.nn.Sequential(torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "                                          # conv2d shape (?, 14, 14, 64)\n",
    "                                          torch.nn.ReLU(),\n",
    "                                          torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "                                          # pool shape (?, 7, 7, 64)\n",
    "                                         )\n",
    "        # 전결합층 7x7x64\n",
    "        self.fc = torch.nn.Linear(7*7*64, 10, bias=True)\n",
    "        \n",
    "        # 전결합층 한정으로 가중치 초기화\n",
    "        torch.nn.init.xavier_uniform_(self.fc.weight)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2506ac15-14af-439c-a82b-c59e172dc1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 정의\n",
    "model = CNN()\n",
    "\n",
    "# 비용함수, 옵티마이저 정의\n",
    "cost = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee55658-1bf8-4e14-9006-a2c4854da9ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 학습\n",
    "for epoch in range(n_epochs):\n",
    "    avg_cost = 0\n",
    "    \n",
    "    for X, Y in data_loader: # X는 미니배치, Y는 레이블\n",
    "        \n",
    "        # 가설\n",
    "        hypothesis = model(X)\n",
    "        \n",
    "        # loss\n",
    "        loss = cost(hypothesis, Y)\n",
    "        \n",
    "        # update\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # avg_cost\n",
    "        avg_cost += loss / len(data_loader)\n",
    "        \n",
    "    print(f'Epoch {epoch}/{n_epochs}\\tCost {avg_cost:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0232e1b-2272-4081-a7bb-fe36d3b9d510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 1, 28, 28])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/limkahyun/opt/anaconda3/envs/sona/lib/python3.8/site-packages/torchvision/datasets/mnist.py:80: UserWarning: test_data has been renamed data\n",
      "  warnings.warn(\"test_data has been renamed data\")\n",
      "/Users/limkahyun/opt/anaconda3/envs/sona/lib/python3.8/site-packages/torchvision/datasets/mnist.py:70: UserWarning: test_labels has been renamed targets\n",
      "  warnings.warn(\"test_labels has been renamed targets\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.986299991607666\n"
     ]
    }
   ],
   "source": [
    "# 테스트\n",
    "with torch.no_grad():\n",
    "    X_test = mnist_test.test_data.view(len(mnist_test), 1, 28, 28).float()\n",
    "    y_test = mnist_test.test_labels\n",
    "    \n",
    "    pred = model(X_test)\n",
    "    correct = torch.argmax(pred, 1) == y_test\n",
    "    accuracy = correct.float().mean()\n",
    "    print('Accuracy:', accuracy.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d9cb2f-cc9e-4468-b977-65c85cc716c2",
   "metadata": {},
   "source": [
    "## 2. 깊은 CNN으로 MNIST 분류하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cb2964b0-9019-48b4-b7b6-bf43e6845047",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4b627291-5eae-4a1e-bad3-9a1350c5345c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파라미터 설정\n",
    "lr = 0.001\n",
    "n_epochs = 15\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0a544a72-d257-4cca-b433-fa61cedba36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 정의\n",
    "mnist_train = dsets.MNIST(root='MNIST_data/',\n",
    "                          train=True,\n",
    "                          transform=transforms.ToTensor(),\n",
    "                          download=True\n",
    "                         )\n",
    "mnist_test = dsets.MNIST(root='MNIST_data/',\n",
    "                         train=False,\n",
    "                         transform=transforms.ToTensor(),\n",
    "                         download=True\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4ab40532-cccb-4160-a9fc-2f09af12811c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터로더 정의\n",
    "data_loader = torch.utils.data.DataLoader(dataset=mnist_train,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True,\n",
    "                                          drop_last=True\n",
    "                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0e1c236f-d224-4efc-a462-4f0bec60130e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 설계\n",
    "class CNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.keep_prob = 0.5  # keep_prob 일부만 학습시킴 (keep_prob=1 전체 학습)\n",
    "        \n",
    "        # input shape (?, 28, 28, 1)\n",
    "        self.layer1 = torch.nn.Sequential(torch.nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
    "                                          # shape (?, 28, 28, 32)\n",
    "                                          torch.nn.ReLU(),\n",
    "                                          torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "                                          # shape (?, 14, 14, 32)\n",
    "                                         )\n",
    "        # input shape (?, 14, 14, 32)\n",
    "        self.layer2 = torch.nn.Sequential(torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "                                          # shape (?, 14, 14, 64)\n",
    "                                          torch.nn.ReLU(),\n",
    "                                          torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "                                          # shape (?, 7, 7, 64)\n",
    "                                         )\n",
    "        # input shape (?, 7, 7, 64)\n",
    "        self.layer3 = torch.nn.Sequential(torch.nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "                                          # shape (?, 7, 7, 128)\n",
    "                                          torch.nn.ReLU(),\n",
    "                                          torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "                                          # shape (?, 3, 3, 128)\n",
    "                                         )\n",
    "        # flatten (size(0), 3*3*128), output 625\n",
    "        self.fc1 = torch.nn.Linear(3*3*128, 625, bias=True)\n",
    "        \n",
    "        # 초기화\n",
    "        torch.nn.init.xavier_uniform_(self.fc1.weight)\n",
    "        \n",
    "        # input (?, 3, 3, 128)\n",
    "        self.layer4 = torch.nn.Sequential(self.fc1,\n",
    "                                          # flatten shape (?, 625)\n",
    "                                          torch.nn.ReLU(),\n",
    "                                          torch.nn.Dropout(p=1-self.keep_prob)\n",
    "                                         )\n",
    "        # input (?, 625) outout (?, 10(mnist분류갯수))\n",
    "        self.fc2 = torch.nn.Linear(625, 10, bias=True)\n",
    "        torch.nn.init.xavier_uniform_(self.fc2.weight)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.layer4(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2e45958d-13cb-4dc5-93b6-6f1ee430aef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 정의\n",
    "model = CNN()\n",
    "\n",
    "# 비용함수, 옵티마이저\n",
    "cost = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "99a6698f-6a57-47c3-9bbe-419415f2a5f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total batch: 600\n",
      "total train data: 60000\n"
     ]
    }
   ],
   "source": [
    "# 총배치 및 총 훈련데이터\n",
    "total_batch = len(data_loader)\n",
    "print('total batch:', total_batch)\n",
    "print('total train data:', total_batch * batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5bf6e0f0-8342-4642-b802-6f3e1fb605dd",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [23]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# update\u001b[39;00m\n\u001b[1;32m     14\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 15\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     18\u001b[0m avg_cost \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m/\u001b[39mtotal_batch\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/sona/lib/python3.8/site-packages/torch/_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    389\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    390\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    394\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    395\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 396\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/sona/lib/python3.8/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 모델 학습\n",
    "for epoch in range(n_epochs):\n",
    "    avg_cost = 0\n",
    "    \n",
    "    for X, y in data_loader: # X 미니배치, y 레이블\n",
    "        \n",
    "        # model\n",
    "        h = model(X)\n",
    "        \n",
    "        # loss\n",
    "        loss = cost(h, y)\n",
    "        \n",
    "        # update\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        avg_cost += loss/total_batch\n",
    "        \n",
    "    print(f'Epoch {epoch}/{n_epochs}\\tCost {avg_cost:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3705b6be-6d6d-453c-9d9c-e22cbf68e9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트\n",
    "with torch.no_grad():\n",
    "    X_test = mnist_test.test_data.view(len(mnist_test), 1, 28, 28).float()\n",
    "    y_test = mnist_test.test_labels\n",
    "    \n",
    "    pred = model(X_test)\n",
    "    correct = torch.argmax(pred, 1) == y_test\n",
    "    accuracy = correct.float().mean()\n",
    "    print('Accuracy:', accuracy.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482f0dcb-dac1-4cd4-b677-2a81d5ffb4b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sona",
   "language": "python",
   "name": "sona"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
